# 1.1 聚类的目标与基本概念

## 目标：在无标签数据中，把“相似”的样本自动归为一组（簇）。

## 关键元素：

### 表示（Representation）：特征如何提取与标准化（数值、类别、文本、图像…）。

### 相似性度量：欧氏距离、曼哈顿距离、余弦相似度、马氏距离、核相似度等。

### 簇形状假设：球形/凸、非凸、密度可分、层次结构、图结构等。

### 目标函数/准则：如簇内平方和最小、似然最大、密度连通、图割最小等。

# 🧩 一、核心概念

## 聚类

### 硬聚类（Hard Clustering）

#### 每个样本只能属于一个簇。“你必须选一个队伍加入。”

#### 👉 代表算法：K-Means, K-Medoids, Agglomerative Clustering, DBSCAN, 谱聚类。

#### 代码实现

##### K-Means

```
from sklearn.cluster import KMeans
  import numpy as np

  X = np.array([[1,2],[1,4],[4,4],[4,1]])
  km = KMeans(n_clusters=2, random_state=0).fit(X)

  print("硬聚类标签:", km.labels_)
```

```
硬聚类标签: [0 0 1 1]
```



### 软聚类（Soft Clustering）	

#### 每个样本对不同簇都有一个隶属度或概率，可以部分属于多个簇。“你可以属于多个团队，只是参与程度不同。”

#### 👉 代表算法：Gaussian Mixture Model (GMM)、Fuzzy C-Means。

##### GMM

```
from sklearn.mixture import GaussianMixture

gm = GaussianMixture(n_components=2, random_state=0).fit(X)
print("预测的簇标签:", gm.predict(X))
print("软聚类隶属度（概率）:\n", gm.predict_proba(X))
```

```
预测的簇标签: [0 0 1 1]
软聚类隶属度（概率）:
[[0.95 0.05]
 [0.90 0.10]
 [0.08 0.92]
 [0.10 0.90]]
```

## 🧭 五、何时用硬聚类、何时用软聚类？

| 场景                                           | 推荐方式             | 原因                 |
| ---------------------------------------------- | -------------------- | -------------------- |
| 业务需要明确分类（如客户分群）                 | **硬聚类**           | 可操作性强，易解释   |
| 数据存在重叠区域或模糊边界（如图像、文本主题） | **软聚类**           | 概率表达更自然       |
| 想识别异常、边界点                             | **软聚类**（用概率） | 低置信度样本可当异常 |
| 聚类用于下游预测或风险打分                     | **软聚类**           | 概率可直接作为特征   |
| 速度要求高、数据大                             | **硬聚类**           | 计算简单，线性收敛   |
